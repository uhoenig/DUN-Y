---
title: "American style Options - Regression methods on Pricing"
author: "Team DUNY Dom, Uwe, Niti, YQ"
date: "April 2016"
output: beamer_presentation
---

```{r, echo=FALSE, message=FALSE}
#generate the process sample space(merged binomial tree)
sim.Price_Bin <- function(N=50, u=3/2, d=2/3, x0 =1){
  x <- matrix(0, nrow = N+1, ncol = N+1)
  
  for(i in 1: (N+1)){
    for(j in 1:i){
      x[i, j]=x0*u^(j-1)*d^(i-j)
    
    }
    
  }
  return(x)
  
}


#generate the corresponding probability
sim.Prob_Bin <- function(N=50, p = 0.4121){
  pi <- matrix(0, nrow = N+1, ncol = N+1)
  
  for(i in 1: (N+1)){
    for(j in 1:i){
      pi[i,j] <- dbinom(x = j-1, size = i-1, prob = p )
      
    }
    
  }
  return(pi)
  
}


#payoff function
g <- function(x, strike = 1){
  return(pmax(0, strike - x))
  
}


#Expectation operator 
P <- function(state, p = 0.4121){
  return(sum(state*c(1-p, p)))
  
}


#some parameters
x_strike <- 1
alpha <- 0.99
p = 0.4121
x0=1.1
u = 3/2
d = 2/3


#exact value of J
J.exact <- function(N=25,...){
  J <- matrix(0, nrow = N+1, ncol = N+1)

  J[N+1,] <- g(x[N+1,],x_strike)
  
  for(i in N:1){
    for(j in 1:i){
      J[i,j] <- pmax(g(x[i,j],x_strike), alpha * P(J[i+1,c(j,j+1)],p))
      
    }
    
  }
  return(J[1,1])
  
}


#exact Q function
Q.exact <- function(N=25,...){
  Q <- matrix(0, nrow = N+1, ncol = N+1)
  
  Q[N+1,] <- g(x[N+1,],x_strike)
  
  for(j in 1:N){
    Q[N, j] <- alpha * P(Q[N+1,c(j,j+1)], p)
    
  }
  
  for(i in (N-1):1){
    for(j in 1:i){
      Q[i,j] <- alpha * P(pmax(g(x[i+1,c(j, j+1)],x_strike), Q[i+1,c(j,j+1)]), p)
      
    }
    
  }
  return(Q[1,1])
  
}


##Regression with fictitious pi
dim <- 3
S <- seq(from = 0.1, to = 2, by = 0.1)


#feature mapping
phi1 <- function(x){
  return(rep(1, length(x)))
  
}


phi2 <- function(x){
  return(x)
  
}


phi3 <- function(x){
  return(x^2)
  
}


#conbind features to get input matrix
phi <- function(x, dim = 3, base = list(phi1, phi2, phi3)){
  base_Mat <- matrix(0, nrow = length(x), ncol = dim)
  
  for( j in 1:dim){
    base_Mat[,j] <- base[[j]](x)
    
  }
  return(base_Mat)
  
}


#Regression with gussing probability
Q1.approx <- function(N=25,...){
  r <- matrix(0, ncol = N, nrow = dim )
  Q1 <- matrix(0, nrow = N, ncol = length(S))
  
  for(j in 1:length(S)){
    Q1[N, j] <- alpha * P(g(c(S[j]*d, S[j]*u)),p)
    
  }
  
  r[, N] <- solve((t(phi(S)) %*% phi(S)), t(phi(S)) %*% Q1[N,])
  
  for (i in (N-1):1){
    for(j in 1:length(S)){
      
      Q1[i, j] <- alpha*P(pmax(g(c(S[j]*d, S[j]*u)), 
                               c(phi(S[j]*d) %*% r[,i+1], phi(S[j]*u) %*% r[,i+1])))
      
    }
    
    r[, i] <- solve((t(phi(S)) %*% phi(S)), t(phi(S)) %*% Q1[i,])
    
  }
  Q1_0 <- phi(S[11]) %*% r[,1]
  return(Q1_0)
  
}


#Regression with true probability
Q2.approx.pop <- function(N=25,...){
  r2 <- matrix(0, ncol = N, nrow = dim )
  Q2<- matrix(0, nrow = N, ncol =  N)
  
  for(j in 1:N){
    Q2[N, j] <- alpha * P(g(x[N+1,])[c(j,j+1)], p)
    
  }
  
  r2[,N] <- solve(t(phi(x[N,1:N])) %*% (phi(x[N, 1:N])*pi[N,1:N]), 
                  t(phi(x[N, 1:N]))%*% (Q2[N,1:N] *pi[N,1:N])) 
  
  Q2[N,] <- phi(x[N,1:N]) %*% r2[,N]
  
  for(i in (N-1):dim){
    for(j in 1:i){
      Q2[i,j] <- alpha * P(pmax(g(x[i+1,c(j, j+1)]), Q2[i+1,c(j,j+1)]), p)
      
    }
    
    r2[,i] <- solve(t(phi(x[i,1:i])) %*% (phi(x[i,1:i]) * pi[i,1:i]),
                    t(phi(x[i, 1:i])) %*% (Q2[i, 1:i]* pi[i,1:i]))
    
    Q2[i, 1:i ] <- phi(x[i,1:i]) %*% r2[,i]
    
  }
  
  for(i in (dim-1):1){
    for(j in 1:i){
      Q2[i,j] <- alpha * P(pmax(g(x[i+1,c(j, j+1)]), Q2[i+1,c(j,j+1)]), p)
      
    }
    
  }
  return(Q2[1,1])
  
}


#simulate trajectories
sim.Trajectory <- function(m = 10, N=25, x0 = 1.1,...){
  traj <- matrix(0, nrow = m, ncol = N+1)
  traj[,1] <- x0
  
  for(j in 2:ncol(traj)){
    traj[,j] <- traj[,j-1]*ifelse(rbinom(m,1,prob = p), u, d)
    
  }
  return(traj)
  
}


#Regression with sampling from true probability
Q3.approx.sim <- function(N=25,m=10,...){
  r3 <- matrix(0, ncol = N, nrow = dim )
  
  Q3<- matrix(0, nrow = N, ncol =  m)
  
  for(j in 1:m){
    Q3[N,j] <- alpha * g(traj[j,N+1])
    
  }
  
  r3[,N] <- solve(t(phi(traj[,N])) %*% phi(traj[,N]), 
                  t(phi(traj[,N])) %*% Q3[N,])
  
  Q3[N,] <- phi(traj[,N]) %*% r3[,N]
  
  for(i in (N-1):dim){
    for(j in 1:m){
      Q3[i,j] <- alpha * pmax(g(traj[j,i+1]), Q3[i+1, j])
      
    }
    
    r3[,i] <- solve(t(phi(traj[,i])) %*% phi(traj[,i]), 
                    t(phi(traj[,i])) %*% Q3[i,])
    
    Q3[i,] <- phi(traj[,i]) %*% r3[,i]
    
  }
  
  for(i in (dim-1):1){
    Q3[i,] <- phi(traj[,i]) %*% r3[,dim] 
    
  }
  return(Q3[1,1])
  
}


#Caculate
Q_collect <-numeric(30-dim)
Q1_collect <-numeric(30-dim)
Q2_collect <- numeric(30-dim)
Q3_collect <- matrix(0, nrow = 30-dim, ncol = 4 )


#simulation sample size
m <- c(10, 25, 50, 100)

for(N in 4:30){
  x <- sim.Price_Bin(N=N, x0 = x0)
  
  pi <- sim.Prob_Bin(N=N, p = p)
  
  Q_collect[N-dim]<- Q.exact(N=N)
  
  Q1_collect[N-dim] <- Q1.approx(N=N)
  
  Q2_collect[N-dim] <- Q2.approx.pop(N=N)
  
  for(j in 1:length(m)){
    set.seed(1111)
    traj <- sim.Trajectory(N=N, m=m[j])
    
    Q3_collect[N-dim,j] <- Q3.approx.sim(N=N,m = m[j])

  }
  
}

library(ggplot2)
library(reshape2)

```

## Introduction

- simulation-based approximate dynamic programming method for pricing complex American-style options
- starting point the binomial option pricing model
- extended analysis by using regression methods
- methods involve the evaluation of value functions at a finite set, consisting of “representative” elements of the state space

## American Style Option

- gives the holder the right to exercise at any time during the contract period
- holder of call(put) option may buy(sell) the underlying asset $S$ at a prescribed price $K$ (strike price)
- the exercise time $\tau$ can be represented as a stopping time
- option price determined by computing the discounted expectated payoff of the option under a risk-neutral measure

## Define Problem

The price of the option is given by:  
$$\sup_{\tau \in [0,\cal{T}]}\mathbb{E}[e^{-r\tau}g(x_\tau)]$$  
where  

* $\lbrace x_\tau \in \Re^d | 0\leq t \leq \cal{T} \rbrace$ - risk-neutral process, assumed to be Markov 
* $r$ - risk-free interest rate, assumed to be a known constant 
* $g(x)$ - intrinsic value of the option when the state is $x$ 
* $\cal{T}$ - expiration time, and the supremum is taken over stopping times that assume values in $[0,\cal{T}]$ 

## Option Price

- Without loss of generality, assume $\mathcal{T}$ equal to integer $N$, and that allowable exercise times seperated by unit length time intervals.

- The price of this option is then:  
$$\sup_{\tau}\mathbb{E}[\alpha^{\tau}g(x_{\tau})]$$
where $\alpha = e^{-r}$

In this discrete-time and Markovian formulation, the dynamics of the risk-neutral process can be described by a transition operator $P$, defined by:
$$(PJ)(x) = \mathbb{E}[J(x_{n+1})| x_n=x]$$

## Dynamics

## Approximations

## Exponential Growth Rate

```{r, echo=FALSE}

tbl <- data.frame(N=4:30, Q=Q_collect, Q1=Q1_collect)
tbl <- melt(tbl, id.vars = "N", variable.name = "type")


ggplot(aes(x = N, y = value, color = type), data = tbl)+
  geom_line()+
  theme_bw()+
  ggtitle("Exponential Growth of Unlucky Regression")

```

## Square Root Growth Rate

```{r, echo=FALSE}
tbl2 <- data.frame(N=4:30, Q=Q_collect, Q2=Q2_collect)
tbl2 <- melt(tbl2, id.vars = "N", variable.name = "type")


ggplot(aes(x = N, y = value, color = type), data = tbl2)+
  geom_line()+
  theme_bw()+
  ggtitle("Square Root Growth of True Regression")

```

## Sampling Method

```{r, echo=FALSE}
tbl3 <- data.frame(N=4:30, Q=Q_collect, 
                   Q3_m10 = Q3_collect[,1],
                   Q3_m25 = Q3_collect[,2],
                   Q3_m50 = Q3_collect[,3],
                   Q3_m100 = Q3_collect[,4])
tbl3 <- melt(tbl3, id.vars = "N", variable.name = "type")


ggplot(aes(x = N, y = value, color = type), data = tbl3)+
  geom_line()+
  theme_bw() +
  ggtitle("Sampling Method")
```